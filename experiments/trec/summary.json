{
    "train": {
        "loss": 0.14808031212966427,
        "acc": 0.9542527956624873
    },
    "dev": {
        "loss": 0.3217716789841652,
        "acc": 0.901
    },
    "test": {
        "loss": 0.3271905028820038,
        "acc": 0.9015
    },
    "trec&cr_topk=1_nh=1": {
        "accuracy": 0.957,
        "dev_trec": {
            "precision": 0.9653767820773931,
            "recall": 0.948,
            "f1-score": 0.9566094853683148,
            "support": 1000
        },
        "dev_cr": {
            "precision": 0.9489194499017681,
            "recall": 0.966,
            "f1-score": 0.9573835480673935,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.968,
            "f1-score": 0.983739837398374,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9735,
            "f1-score": 0.9865720800608057,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9295,
            "f1-score": 0.9634620367970977,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.918,
            "f1-score": 0.9572471324296141,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9645,
            "f1-score": 0.9819292440824637,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9485,
            "f1-score": 0.9735694123684885,
            "support": 2000
        }
    },
    "trec&cr_topk=1_nh=5": {
        "accuracy": 0.9835,
        "dev_trec": {
            "precision": 0.985929648241206,
            "recall": 0.981,
            "f1-score": 0.9834586466165413,
            "support": 1000
        },
        "dev_cr": {
            "precision": 0.981094527363184,
            "recall": 0.986,
            "f1-score": 0.9835411471321694,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.986,
            "f1-score": 0.9929506545820745,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.998,
            "f1-score": 0.998998998998999,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.947,
            "f1-score": 0.9727786337955828,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.94,
            "f1-score": 0.9690721649484536,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.953,
            "f1-score": 0.9759344598054276,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.968,
            "f1-score": 0.983739837398374,
            "support": 2000
        }
    },
    "trec&cr_topk=1_nh=13": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_cr": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.986,
            "f1-score": 0.9929506545820745,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.788,
            "f1-score": 0.8814317673378076,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9665,
            "f1-score": 0.9829646580218663,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.958,
            "f1-score": 0.9785495403472931,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9725,
            "f1-score": 0.9860583016476552,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.993,
            "f1-score": 0.9964877069744105,
            "support": 2000
        }
    },
    "trec&cr_topk=1_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_cr": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.986,
            "f1-score": 0.9929506545820745,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.7825,
            "f1-score": 0.8779803646563815,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.967,
            "f1-score": 0.9832231825114387,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9575,
            "f1-score": 0.9782886334610472,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9725,
            "f1-score": 0.9860583016476552,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.993,
            "f1-score": 0.9964877069744105,
            "support": 2000
        }
    },
    "trec&cr_topk=2_nh=1": {
        "accuracy": 0.961,
        "dev_trec": {
            "precision": 0.9694501018329938,
            "recall": 0.952,
            "f1-score": 0.9606458123107972,
            "support": 1000
        },
        "dev_cr": {
            "precision": 0.9528487229862476,
            "recall": 0.97,
            "f1-score": 0.9613478691774034,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9705,
            "f1-score": 0.9850291804110632,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.975,
            "f1-score": 0.9873417721518987,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9275,
            "f1-score": 0.9623865110246433,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.919,
            "f1-score": 0.9577905158936947,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.963,
            "f1-score": 0.9811512990320936,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.949,
            "f1-score": 0.9738327347357619,
            "support": 2000
        }
    },
    "trec&cr_topk=2_nh=5": {
        "accuracy": 0.9855,
        "dev_trec": {
            "precision": 0.9869608826479438,
            "recall": 0.984,
            "f1-score": 0.985478217325989,
            "support": 1000
        },
        "dev_cr": {
            "precision": 0.9840478564307079,
            "recall": 0.987,
            "f1-score": 0.9855217174238642,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.984,
            "f1-score": 0.9919354838709677,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.996,
            "f1-score": 0.9979959919839679,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.949,
            "f1-score": 0.9738327347357619,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9495,
            "f1-score": 0.97409592203129,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9525,
            "f1-score": 0.9756722151088347,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9715,
            "f1-score": 0.985544002028912,
            "support": 2000
        }
    },
    "trec&cr_topk=2_nh=13": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_cr": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9935,
            "f1-score": 0.9967394030599448,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.652,
            "f1-score": 0.7893462469733655,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9795,
            "f1-score": 0.9896438494569336,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.978,
            "f1-score": 0.9888776541961577,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.982,
            "f1-score": 0.9909182643794148,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9925,
            "f1-score": 0.9962358845671266,
            "support": 2000
        }
    },
    "trec&cr_topk=2_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_cr": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.995,
            "f1-score": 0.9974937343358395,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.777,
            "f1-score": 0.8745075970737197,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9755,
            "f1-score": 0.9875980764363452,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.981,
            "f1-score": 0.9904088844018173,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9795,
            "f1-score": 0.9896438494569336,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9935,
            "f1-score": 0.9967394030599448,
            "support": 2000
        }
    },
    "trec&mpqa_topk=1_nh=1": {
        "accuracy": 0.957,
        "dev_trec": {
            "precision": 0.9579158316633266,
            "recall": 0.956,
            "f1-score": 0.9569569569569569,
            "support": 1000
        },
        "dev_mpqa": {
            "precision": 0.9560878243512974,
            "recall": 0.958,
            "f1-score": 0.9570429570429569,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.95,
            "f1-score": 0.9743589743589743,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.963,
            "f1-score": 0.9811512990320936,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.893,
            "f1-score": 0.9434759640781828,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.885,
            "f1-score": 0.9389920424403183,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.943,
            "f1-score": 0.970663921770458,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.957,
            "f1-score": 0.9780275932549821,
            "support": 2000
        }
    },
    "trec&mpqa_topk=1_nh=5": {
        "accuracy": 0.9965,
        "dev_trec": {
            "precision": 0.996996996996997,
            "recall": 0.996,
            "f1-score": 0.9964982491245623,
            "support": 1000
        },
        "dev_mpqa": {
            "precision": 0.996003996003996,
            "recall": 0.997,
            "f1-score": 0.9965017491254373,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.6245,
            "f1-score": 0.7688519544475223,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.996,
            "f1-score": 0.9979959919839679,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.443,
            "f1-score": 0.613998613998614,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.4495,
            "f1-score": 0.6202138668506382,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.4775,
            "f1-score": 0.6463620981387478,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9925,
            "f1-score": 0.9962358845671266,
            "support": 2000
        }
    },
    "trec&mpqa_topk=1_nh=13": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_mpqa": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.3035,
            "f1-score": 0.46566935174530105,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9935,
            "f1-score": 0.9967394030599448,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.3125,
            "f1-score": 0.47619047619047616,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.354,
            "f1-score": 0.5228951255539143,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.299,
            "f1-score": 0.4603541185527329,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.998,
            "f1-score": 0.998998998998999,
            "support": 2000
        }
    },
    "trec&mpqa_topk=1_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_mpqa": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.3415,
            "f1-score": 0.5091315691390236,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9915,
            "f1-score": 0.9957318604067287,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.3305,
            "f1-score": 0.4968057121382939,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.3605,
            "f1-score": 0.529952223447262,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.3715,
            "f1-score": 0.5417426175720015,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.998,
            "f1-score": 0.998998998998999,
            "support": 2000
        }
    },
    "trec&mpqa_topk=2_nh=1": {
        "accuracy": 0.9585,
        "dev_trec": {
            "precision": 0.9571286141575274,
            "recall": 0.96,
            "f1-score": 0.9585621567648526,
            "support": 1000
        },
        "dev_mpqa": {
            "precision": 0.9598796389167502,
            "recall": 0.957,
            "f1-score": 0.958437656484727,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9515,
            "f1-score": 0.9751473225723802,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9655,
            "f1-score": 0.9824472144492495,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.893,
            "f1-score": 0.9434759640781828,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.8885,
            "f1-score": 0.9409584326184802,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.943,
            "f1-score": 0.970663921770458,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.958,
            "f1-score": 0.9785495403472931,
            "support": 2000
        }
    },
    "trec&mpqa_topk=2_nh=5": {
        "accuracy": 0.9985,
        "dev_trec": {
            "precision": 0.998998998998999,
            "recall": 0.998,
            "f1-score": 0.9984992496248123,
            "support": 1000
        },
        "dev_mpqa": {
            "precision": 0.998001998001998,
            "recall": 0.999,
            "f1-score": 0.9985007496251873,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.7055,
            "f1-score": 0.8273233655819408,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.5525,
            "f1-score": 0.7117552334943639,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.5555,
            "f1-score": 0.7142397942783671,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.591,
            "f1-score": 0.742928975487115,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.994,
            "f1-score": 0.9969909729187563,
            "support": 2000
        }
    },
    "trec&mpqa_topk=2_nh=13": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_mpqa": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.3475,
            "f1-score": 0.5157699443413729,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.346,
            "f1-score": 0.5141158989598811,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.379,
            "f1-score": 0.5496736765772299,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.3495,
            "f1-score": 0.5179696183771767,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9985,
            "f1-score": 0.9992494370778084,
            "support": 2000
        }
    },
    "trec&mpqa_topk=2_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_mpqa": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.3395,
            "f1-score": 0.5069055617767824,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.34,
            "f1-score": 0.5074626865671642,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.367,
            "f1-score": 0.5369422092172641,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.396,
            "f1-score": 0.5673352435530087,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.998,
            "f1-score": 0.998998998998999,
            "support": 2000
        }
    },
    "trec&mr_topk=1_nh=1": {
        "accuracy": 0.9425,
        "dev_trec": {
            "precision": 0.949238578680203,
            "recall": 0.935,
            "f1-score": 0.942065491183879,
            "support": 1000
        },
        "dev_mr": {
            "precision": 0.9359605911330049,
            "recall": 0.95,
            "f1-score": 0.9429280397022333,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9845,
            "f1-score": 0.9921894683799445,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9815,
            "f1-score": 0.9906636386575827,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9545,
            "f1-score": 0.9767203888462523,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.946,
            "f1-score": 0.9722507708119219,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.98,
            "f1-score": 0.98989898989899,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9385,
            "f1-score": 0.9682744389992263,
            "support": 2000
        }
    },
    "trec&mr_topk=1_nh=5": {
        "accuracy": 0.977,
        "dev_trec": {
            "precision": 0.9798792756539235,
            "recall": 0.974,
            "f1-score": 0.9769307923771314,
            "support": 1000
        },
        "dev_mr": {
            "precision": 0.974155069582505,
            "recall": 0.98,
            "f1-score": 0.9770687936191426,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.99,
            "f1-score": 0.9949748743718593,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.999,
            "f1-score": 0.9994997498749374,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.975,
            "f1-score": 0.9873417721518987,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.968,
            "f1-score": 0.983739837398374,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.973,
            "f1-score": 0.9863152559553979,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9555,
            "f1-score": 0.9772436716952186,
            "support": 2000
        }
    },
    "trec&mr_topk=1_nh=13": {
        "accuracy": 0.997,
        "dev_trec": {
            "precision": 0.998995983935743,
            "recall": 0.995,
            "f1-score": 0.9969939879759518,
            "support": 1000
        },
        "dev_mr": {
            "precision": 0.9950199203187251,
            "recall": 0.999,
            "f1-score": 0.9970059880239521,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.682,
            "f1-score": 0.8109393579072534,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.992,
            "f1-score": 0.9959839357429718,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.991,
            "f1-score": 0.9954796584630838,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.992,
            "f1-score": 0.9959839357429718,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.993,
            "f1-score": 0.9964877069744105,
            "support": 2000
        }
    },
    "trec&mr_topk=1_nh=14": {
        "accuracy": 0.997,
        "dev_trec": {
            "precision": 0.998995983935743,
            "recall": 0.995,
            "f1-score": 0.9969939879759518,
            "support": 1000
        },
        "dev_mr": {
            "precision": 0.9950199203187251,
            "recall": 0.999,
            "f1-score": 0.9970059880239521,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.6855,
            "f1-score": 0.8134084841293385,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.992,
            "f1-score": 0.9959839357429718,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.991,
            "f1-score": 0.9954796584630838,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.992,
            "f1-score": 0.9959839357429718,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.993,
            "f1-score": 0.9964877069744105,
            "support": 2000
        }
    },
    "trec&mr_topk=2_nh=1": {
        "accuracy": 0.9425,
        "dev_trec": {
            "precision": 0.949238578680203,
            "recall": 0.935,
            "f1-score": 0.942065491183879,
            "support": 1000
        },
        "dev_mr": {
            "precision": 0.9359605911330049,
            "recall": 0.95,
            "f1-score": 0.9429280397022333,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.985,
            "f1-score": 0.9924433249370278,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9825,
            "f1-score": 0.991172761664565,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9555,
            "f1-score": 0.9772436716952186,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9485,
            "f1-score": 0.9735694123684885,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.981,
            "f1-score": 0.9904088844018173,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.938,
            "f1-score": 0.9680082559339525,
            "support": 2000
        }
    },
    "trec&mr_topk=2_nh=5": {
        "accuracy": 0.978,
        "dev_trec": {
            "precision": 0.9808853118712274,
            "recall": 0.975,
            "f1-score": 0.9779338014042126,
            "support": 1000
        },
        "dev_mr": {
            "precision": 0.9751491053677932,
            "recall": 0.981,
            "f1-score": 0.9780658025922233,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.993,
            "f1-score": 0.9964877069744105,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.994,
            "f1-score": 0.9969909729187563,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9795,
            "f1-score": 0.9896438494569336,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.973,
            "f1-score": 0.9863152559553979,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.979,
            "f1-score": 0.989388580090955,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9605,
            "f1-score": 0.9798520785513899,
            "support": 2000
        }
    },
    "trec&mr_topk=2_nh=13": {
        "accuracy": 0.9985,
        "dev_trec": {
            "precision": 0.998998998998999,
            "recall": 0.998,
            "f1-score": 0.9984992496248123,
            "support": 1000
        },
        "dev_mr": {
            "precision": 0.998001998001998,
            "recall": 0.999,
            "f1-score": 0.9985007496251873,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9885,
            "f1-score": 0.9942167462911742,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.543,
            "f1-score": 0.7038237200259235,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.987,
            "f1-score": 0.9934574735782586,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.989,
            "f1-score": 0.9944695827048768,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9875,
            "f1-score": 0.9937106918238994,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.986,
            "f1-score": 0.9929506545820745,
            "support": 2000
        }
    },
    "trec&mr_topk=2_nh=14": {
        "accuracy": 0.9985,
        "dev_trec": {
            "precision": 0.998998998998999,
            "recall": 0.998,
            "f1-score": 0.9984992496248123,
            "support": 1000
        },
        "dev_mr": {
            "precision": 0.998001998001998,
            "recall": 0.999,
            "f1-score": 0.9985007496251873,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9875,
            "f1-score": 0.9937106918238994,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.569,
            "f1-score": 0.7253027405991077,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.988,
            "f1-score": 0.993963782696177,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9895,
            "f1-score": 0.9947222920331742,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.988,
            "f1-score": 0.993963782696177,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9895,
            "f1-score": 0.9947222920331742,
            "support": 2000
        }
    },
    "trec&sst2_topk=1_nh=1": {
        "accuracy": 0.946,
        "dev_trec": {
            "precision": 0.9569672131147541,
            "recall": 0.934,
            "f1-score": 0.9453441295546559,
            "support": 1000
        },
        "dev_sst2": {
            "precision": 0.935546875,
            "recall": 0.958,
            "f1-score": 0.9466403162055336,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9855,
            "f1-score": 0.9926970536388819,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9825,
            "f1-score": 0.991172761664565,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.96,
            "f1-score": 0.9795918367346939,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9505,
            "f1-score": 0.9746218918226096,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.982,
            "f1-score": 0.9909182643794148,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9375,
            "f1-score": 0.967741935483871,
            "support": 2000
        }
    },
    "trec&sst2_topk=1_nh=5": {
        "accuracy": 0.968,
        "dev_trec": {
            "precision": 0.9708249496981891,
            "recall": 0.965,
            "f1-score": 0.9679037111334001,
            "support": 1000
        },
        "dev_sst2": {
            "precision": 0.9652087475149106,
            "recall": 0.971,
            "f1-score": 0.9680957128614158,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9925,
            "f1-score": 0.9962358845671266,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9995,
            "f1-score": 0.9997499374843711,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.982,
            "f1-score": 0.9909182643794148,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.973,
            "f1-score": 0.9863152559553979,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.98,
            "f1-score": 0.98989898989899,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9525,
            "f1-score": 0.9756722151088347,
            "support": 2000
        }
    },
    "trec&sst2_topk=1_nh=13": {
        "accuracy": 0.9955,
        "dev_trec": {
            "precision": 0.995995995995996,
            "recall": 0.995,
            "f1-score": 0.9954977488744372,
            "support": 1000
        },
        "dev_sst2": {
            "precision": 0.995004995004995,
            "recall": 0.996,
            "f1-score": 0.9955022488755622,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9975,
            "f1-score": 0.9987484355444306,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.871,
            "f1-score": 0.9310529128808124,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9965,
            "f1-score": 0.9982469321312296,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9915,
            "f1-score": 0.9957318604067287,
            "support": 2000
        }
    },
    "trec&sst2_topk=1_nh=14": {
        "accuracy": 0.9955,
        "dev_trec": {
            "precision": 0.995995995995996,
            "recall": 0.995,
            "f1-score": 0.9954977488744372,
            "support": 1000
        },
        "dev_sst2": {
            "precision": 0.995004995004995,
            "recall": 0.996,
            "f1-score": 0.9955022488755622,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9975,
            "f1-score": 0.9987484355444306,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.8745,
            "f1-score": 0.9330488130168045,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9975,
            "f1-score": 0.9987484355444306,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9945,
            "f1-score": 0.997242416645776,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9915,
            "f1-score": 0.9957318604067287,
            "support": 2000
        }
    },
    "trec&sst2_topk=2_nh=1": {
        "accuracy": 0.946,
        "dev_trec": {
            "precision": 0.9579055441478439,
            "recall": 0.933,
            "f1-score": 0.9452887537993921,
            "support": 1000
        },
        "dev_sst2": {
            "precision": 0.9346978557504874,
            "recall": 0.959,
            "f1-score": 0.9466929911154985,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.987,
            "f1-score": 0.9934574735782586,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9835,
            "f1-score": 0.991681371313335,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9595,
            "f1-score": 0.9793314621076805,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9525,
            "f1-score": 0.9756722151088347,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.982,
            "f1-score": 0.9909182643794148,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.936,
            "f1-score": 0.9669421487603307,
            "support": 2000
        }
    },
    "trec&sst2_topk=2_nh=5": {
        "accuracy": 0.975,
        "dev_trec": {
            "precision": 0.9788306451612904,
            "recall": 0.971,
            "f1-score": 0.9748995983935743,
            "support": 1000
        },
        "dev_sst2": {
            "precision": 0.9712301587301587,
            "recall": 0.979,
            "f1-score": 0.9750996015936254,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9945,
            "f1-score": 0.997242416645776,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.999,
            "f1-score": 0.9994997498749374,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.985,
            "f1-score": 0.9924433249370278,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9795,
            "f1-score": 0.9896438494569336,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9845,
            "f1-score": 0.9921894683799445,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9515,
            "f1-score": 0.9751473225723802,
            "support": 2000
        }
    },
    "trec&sst2_topk=2_nh=13": {
        "accuracy": 0.998,
        "dev_trec": {
            "precision": 0.9970059880239521,
            "recall": 0.999,
            "f1-score": 0.998001998001998,
            "support": 1000
        },
        "dev_sst2": {
            "precision": 0.998997995991984,
            "recall": 0.997,
            "f1-score": 0.997997997997998,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.996,
            "f1-score": 0.9979959919839679,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.972,
            "f1-score": 0.9858012170385395,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.994,
            "f1-score": 0.9969909729187563,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.992,
            "f1-score": 0.9959839357429718,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.991,
            "f1-score": 0.9954796584630838,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.982,
            "f1-score": 0.9909182643794148,
            "support": 2000
        }
    },
    "trec&sst2_topk=2_nh=14": {
        "accuracy": 0.9985,
        "dev_trec": {
            "precision": 0.998001998001998,
            "recall": 0.999,
            "f1-score": 0.9985007496251873,
            "support": 1000
        },
        "dev_sst2": {
            "precision": 0.998998998998999,
            "recall": 0.998,
            "f1-score": 0.9984992496248123,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9965,
            "f1-score": 0.9982469321312296,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9695,
            "f1-score": 0.9845138359989846,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9925,
            "f1-score": 0.9962358845671266,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.99,
            "f1-score": 0.9949748743718593,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.983,
            "f1-score": 0.9914271306101865,
            "support": 2000
        }
    },
    "trec&subj_topk=1_nh=1": {
        "accuracy": 0.9575,
        "dev_trec": {
            "precision": 0.9625884732052579,
            "recall": 0.952,
            "f1-score": 0.9572649572649573,
            "support": 1000
        },
        "dev_subj": {
            "precision": 0.9525222551928784,
            "recall": 0.963,
            "f1-score": 0.95773247140726,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9625,
            "f1-score": 0.980891719745223,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.969,
            "f1-score": 0.984255967496191,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9155,
            "f1-score": 0.9558861915948839,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9005,
            "f1-score": 0.9476453564851354,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.955,
            "f1-score": 0.9769820971867007,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.953,
            "f1-score": 0.9759344598054276,
            "support": 2000
        }
    },
    "trec&subj_topk=1_nh=5": {
        "accuracy": 0.9765,
        "dev_trec": {
            "precision": 0.9798590130916415,
            "recall": 0.973,
            "f1-score": 0.9764174611138986,
            "support": 1000
        },
        "dev_subj": {
            "precision": 0.9731876861966237,
            "recall": 0.98,
            "f1-score": 0.9765819631290483,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.99,
            "f1-score": 0.9949748743718593,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9985,
            "f1-score": 0.9992494370778084,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.973,
            "f1-score": 0.9863152559553979,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9665,
            "f1-score": 0.9829646580218663,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9725,
            "f1-score": 0.9860583016476552,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9555,
            "f1-score": 0.9772436716952186,
            "support": 2000
        }
    },
    "trec&subj_topk=1_nh=13": {
        "accuracy": 0.9965,
        "dev_trec": {
            "precision": 0.996996996996997,
            "recall": 0.996,
            "f1-score": 0.9964982491245623,
            "support": 1000
        },
        "dev_subj": {
            "precision": 0.996003996003996,
            "recall": 0.997,
            "f1-score": 0.9965017491254373,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.618,
            "f1-score": 0.7639060568603214,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9905,
            "f1-score": 0.9952273298166291,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.99,
            "f1-score": 0.9949748743718593,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9935,
            "f1-score": 0.9967394030599448,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.991,
            "f1-score": 0.9954796584630838,
            "support": 2000
        }
    },
    "trec&subj_topk=1_nh=14": {
        "accuracy": 0.9965,
        "dev_trec": {
            "precision": 0.9979939819458375,
            "recall": 0.995,
            "f1-score": 0.9964947421131698,
            "support": 1000
        },
        "dev_subj": {
            "precision": 0.9950149551345963,
            "recall": 0.998,
            "f1-score": 0.9965052421367948,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.5855,
            "f1-score": 0.738568274992116,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.99,
            "f1-score": 0.9949748743718593,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9895,
            "f1-score": 0.9947222920331742,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.994,
            "f1-score": 0.9969909729187563,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.989,
            "f1-score": 0.9944695827048768,
            "support": 2000
        }
    },
    "trec&subj_topk=2_nh=1": {
        "accuracy": 0.961,
        "dev_trec": {
            "precision": 0.9665991902834008,
            "recall": 0.955,
            "f1-score": 0.9607645875251509,
            "support": 1000
        },
        "dev_subj": {
            "precision": 0.9555335968379447,
            "recall": 0.967,
            "f1-score": 0.9612326043737575,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9635,
            "f1-score": 0.9814107461166285,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9705,
            "f1-score": 0.9850291804110632,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.916,
            "f1-score": 0.9561586638830899,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9005,
            "f1-score": 0.9476453564851354,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9545,
            "f1-score": 0.9767203888462523,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.952,
            "f1-score": 0.9754098360655737,
            "support": 2000
        }
    },
    "trec&subj_topk=2_nh=5": {
        "accuracy": 0.9795,
        "dev_trec": {
            "precision": 0.9828801611278952,
            "recall": 0.976,
            "f1-score": 0.9794279979929754,
            "support": 1000
        },
        "dev_subj": {
            "precision": 0.9761668321747765,
            "recall": 0.983,
            "f1-score": 0.979571499750872,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9915,
            "f1-score": 0.9957318604067287,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.991,
            "f1-score": 0.9954796584630838,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.978,
            "f1-score": 0.9888776541961577,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9715,
            "f1-score": 0.985544002028912,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.978,
            "f1-score": 0.9888776541961577,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.963,
            "f1-score": 0.9811512990320936,
            "support": 2000
        }
    },
    "trec&subj_topk=2_nh=13": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_subj": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.993,
            "f1-score": 0.9964877069744105,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.5895,
            "f1-score": 0.7417426863793646,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.988,
            "f1-score": 0.993963782696177,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.988,
            "f1-score": 0.993963782696177,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9885,
            "f1-score": 0.9942167462911742,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.985,
            "f1-score": 0.9924433249370278,
            "support": 2000
        }
    },
    "trec&subj_topk=2_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "dev_subj": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 1000
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9935,
            "f1-score": 0.9967394030599448,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.549,
            "f1-score": 0.7088444157520982,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.985,
            "f1-score": 0.9924433249370278,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9875,
            "f1-score": 0.9937106918238994,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9875,
            "f1-score": 0.9937106918238994,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9845,
            "f1-score": 0.9921894683799445,
            "support": 2000
        }
    }
}