{
    "train": {
        "loss": 0.07599236922604698,
        "acc": 0.977687626360327
    },
    "dev": {
        "loss": 0.32412450122833253,
        "acc": 0.9080000009536743
    },
    "test": {
        "loss": 0.2583505208492279,
        "acc": 0.924
    },
    "trec&cr_topk=1_nh=1": {
        "accuracy": 0.921,
        "dev_trec": {
            "precision": 0.9287169042769857,
            "recall": 0.912,
            "f1-score": 0.9202825428859738,
            "support": 500
        },
        "dev_cr": {
            "precision": 0.9135559921414538,
            "recall": 0.93,
            "f1-score": 0.9217046580773044,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9405,
            "f1-score": 0.9693377995362019,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9695,
            "f1-score": 0.9845138359989846,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9595,
            "f1-score": 0.9793314621076805,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.934,
            "f1-score": 0.9658738366080661,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.972,
            "f1-score": 0.9858012170385395,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9225,
            "f1-score": 0.9596879063719116,
            "support": 2000
        }
    },
    "trec&cr_topk=1_nh=5": {
        "accuracy": 0.96,
        "dev_trec": {
            "precision": 0.9655870445344129,
            "recall": 0.954,
            "f1-score": 0.9597585513078469,
            "support": 500
        },
        "dev_cr": {
            "precision": 0.9545454545454546,
            "recall": 0.966,
            "f1-score": 0.9602385685884691,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.968,
            "f1-score": 0.983739837398374,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.998,
            "f1-score": 0.998998998998999,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.97,
            "f1-score": 0.9847715736040609,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9595,
            "f1-score": 0.9793314621076805,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.98,
            "f1-score": 0.98989898989899,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.959,
            "f1-score": 0.9790709545686574,
            "support": 2000
        }
    },
    "trec&cr_topk=1_nh=14": {
        "accuracy": 0.998,
        "dev_trec": {
            "precision": 1.0,
            "recall": 0.996,
            "f1-score": 0.9979959919839679,
            "support": 500
        },
        "dev_cr": {
            "precision": 0.9960159362549801,
            "recall": 1.0,
            "f1-score": 0.998003992015968,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.997,
            "f1-score": 0.99849774661993,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.917,
            "f1-score": 0.9567031820552947,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.989,
            "f1-score": 0.9944695827048768,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.983,
            "f1-score": 0.9914271306101865,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9905,
            "f1-score": 0.9952273298166291,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9895,
            "f1-score": 0.9947222920331742,
            "support": 2000
        }
    },
    "trec&cr_topk=3_nh=1": {
        "accuracy": 0.927,
        "dev_trec": {
            "precision": 0.981941309255079,
            "recall": 0.87,
            "f1-score": 0.9225874867444328,
            "support": 500
        },
        "dev_cr": {
            "precision": 0.8833034111310593,
            "recall": 0.984,
            "f1-score": 0.9309366130558184,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9745,
            "f1-score": 0.9870853380602685,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9905,
            "f1-score": 0.9952273298166291,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9935,
            "f1-score": 0.9967394030599448,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9905,
            "f1-score": 0.9952273298166291,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9935,
            "f1-score": 0.9967394030599448,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.8935,
            "f1-score": 0.9437549511486665,
            "support": 2000
        }
    },
    "trec&cr_topk=3_nh=5": {
        "accuracy": 0.972,
        "dev_trec": {
            "precision": 0.9738955823293173,
            "recall": 0.97,
            "f1-score": 0.9719438877755512,
            "support": 500
        },
        "dev_cr": {
            "precision": 0.9701195219123506,
            "recall": 0.974,
            "f1-score": 0.9720558882235529,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.978,
            "f1-score": 0.9888776541961577,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9975,
            "f1-score": 0.9987484355444306,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9715,
            "f1-score": 0.985544002028912,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9675,
            "f1-score": 0.9834815756035579,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9815,
            "f1-score": 0.9906636386575827,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9585,
            "f1-score": 0.9788103140158285,
            "support": 2000
        }
    },
    "trec&cr_topk=3_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "dev_cr": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9915,
            "f1-score": 0.9957318604067287,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.782,
            "f1-score": 0.877665544332211,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.966,
            "f1-score": 0.982706002034588,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9695,
            "f1-score": 0.9845138359989846,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.961,
            "f1-score": 0.9801121876593575,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.988,
            "f1-score": 0.993963782696177,
            "support": 2000
        }
    },
    "trec&mpqa_topk=1_nh=1": {
        "accuracy": 0.932,
        "dev_trec": {
            "precision": 0.932,
            "recall": 0.932,
            "f1-score": 0.932,
            "support": 500
        },
        "dev_mpqa": {
            "precision": 0.932,
            "recall": 0.932,
            "f1-score": 0.932,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.8745,
            "f1-score": 0.9330488130168045,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.937,
            "f1-score": 0.9674754775425917,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.908,
            "f1-score": 0.9517819706498952,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.8725,
            "f1-score": 0.9319092122830441,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9425,
            "f1-score": 0.9703989703989705,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.942,
            "f1-score": 0.9701338825952626,
            "support": 2000
        }
    },
    "trec&mpqa_topk=1_nh=5": {
        "accuracy": 0.996,
        "dev_trec": {
            "precision": 0.9940239043824701,
            "recall": 0.998,
            "f1-score": 0.9960079840319361,
            "support": 500
        },
        "dev_mpqa": {
            "precision": 0.9979919678714859,
            "recall": 0.994,
            "f1-score": 0.9959919839679359,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.3775,
            "f1-score": 0.5480943738656987,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.993,
            "f1-score": 0.9964877069744105,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.3575,
            "f1-score": 0.5267034990791897,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.3775,
            "f1-score": 0.5480943738656987,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.4955,
            "f1-score": 0.6626546305583416,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.99,
            "f1-score": 0.9949748743718593,
            "support": 2000
        }
    },
    "trec&mpqa_topk=1_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "dev_mpqa": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.369,
            "f1-score": 0.5390796201607012,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.48,
            "f1-score": 0.6486486486486487,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.4595,
            "f1-score": 0.6296676944158959,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.5985,
            "f1-score": 0.7488270253362528,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        }
    },
    "trec&mpqa_topk=3_nh=1": {
        "accuracy": 0.955,
        "dev_trec": {
            "precision": 0.972972972972973,
            "recall": 0.936,
            "f1-score": 0.9541284403669725,
            "support": 500
        },
        "dev_mpqa": {
            "precision": 0.9383429672447013,
            "recall": 0.974,
            "f1-score": 0.9558390578999019,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.841,
            "f1-score": 0.9136338946224878,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9665,
            "f1-score": 0.9829646580218663,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.901,
            "f1-score": 0.9479221462388217,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.876,
            "f1-score": 0.933901918976546,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.936,
            "f1-score": 0.9669421487603307,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9465,
            "f1-score": 0.9725147701001798,
            "support": 2000
        }
    },
    "trec&mpqa_topk=3_nh=5": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "dev_mpqa": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.606,
            "f1-score": 0.7546699875466999,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9965,
            "f1-score": 0.9982469321312296,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.5715,
            "f1-score": 0.7273305758829145,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.573,
            "f1-score": 0.7285441830896376,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.626,
            "f1-score": 0.7699876998769988,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.987,
            "f1-score": 0.9934574735782586,
            "support": 2000
        }
    },
    "trec&mpqa_topk=3_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "dev_mpqa": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.432,
            "f1-score": 0.6033519553072626,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.995,
            "f1-score": 0.9974937343358395,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.463,
            "f1-score": 0.632946001367054,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.4865,
            "f1-score": 0.6545576858392197,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.4465,
            "f1-score": 0.61735222951953,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.998,
            "f1-score": 0.998998998998999,
            "support": 2000
        }
    },
    "trec&mr_topk=1_nh=1": {
        "accuracy": 0.938,
        "dev_trec": {
            "precision": 0.9524793388429752,
            "recall": 0.922,
            "f1-score": 0.9369918699186993,
            "support": 500
        },
        "dev_mr": {
            "precision": 0.9244186046511628,
            "recall": 0.954,
            "f1-score": 0.9389763779527558,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.913,
            "f1-score": 0.9545216936748563,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.961,
            "f1-score": 0.9801121876593575,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9435,
            "f1-score": 0.9709287368150245,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.916,
            "f1-score": 0.9561586638830899,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.965,
            "f1-score": 0.9821882951653944,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.93,
            "f1-score": 0.9637305699481865,
            "support": 2000
        }
    },
    "trec&mr_topk=1_nh=5": {
        "accuracy": 0.97,
        "dev_trec": {
            "precision": 0.9776422764227642,
            "recall": 0.962,
            "f1-score": 0.969758064516129,
            "support": 500
        },
        "dev_mr": {
            "precision": 0.9625984251968503,
            "recall": 0.978,
            "f1-score": 0.9702380952380953,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9635,
            "f1-score": 0.9814107461166285,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.998,
            "f1-score": 0.998998998998999,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.967,
            "f1-score": 0.9832231825114387,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.955,
            "f1-score": 0.9769820971867007,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.978,
            "f1-score": 0.9888776541961577,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9615,
            "f1-score": 0.9803721641600815,
            "support": 2000
        }
    },
    "trec&mr_topk=1_nh=14": {
        "accuracy": 0.997,
        "dev_trec": {
            "precision": 1.0,
            "recall": 0.994,
            "f1-score": 0.9969909729187563,
            "support": 500
        },
        "dev_mr": {
            "precision": 0.9940357852882704,
            "recall": 1.0,
            "f1-score": 0.9970089730807578,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.995,
            "f1-score": 0.9974937343358395,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9535,
            "f1-score": 0.9761965702585104,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9935,
            "f1-score": 0.9967394030599448,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.985,
            "f1-score": 0.9924433249370278,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9895,
            "f1-score": 0.9947222920331742,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.99,
            "f1-score": 0.9949748743718593,
            "support": 2000
        }
    },
    "trec&mr_topk=3_nh=1": {
        "accuracy": 0.933,
        "dev_trec": {
            "precision": 0.971677559912854,
            "recall": 0.892,
            "f1-score": 0.9301355578727842,
            "support": 500
        },
        "dev_mr": {
            "precision": 0.9001848428835489,
            "recall": 0.974,
            "f1-score": 0.9356388088376562,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.92,
            "f1-score": 0.9583333333333334,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.977,
            "f1-score": 0.9883662114314619,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.978,
            "f1-score": 0.9888776541961577,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9675,
            "f1-score": 0.9834815756035579,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.982,
            "f1-score": 0.9909182643794148,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.905,
            "f1-score": 0.9501312335958005,
            "support": 2000
        }
    },
    "trec&mr_topk=3_nh=5": {
        "accuracy": 0.982,
        "dev_trec": {
            "precision": 0.9878542510121457,
            "recall": 0.976,
            "f1-score": 0.9818913480885312,
            "support": 500
        },
        "dev_mr": {
            "precision": 0.9762845849802372,
            "recall": 0.988,
            "f1-score": 0.9821073558648111,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9445,
            "f1-score": 0.9714579583440472,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9935,
            "f1-score": 0.9967394030599448,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.968,
            "f1-score": 0.983739837398374,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.962,
            "f1-score": 0.9806320081549439,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9795,
            "f1-score": 0.9896438494569336,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9665,
            "f1-score": 0.9829646580218663,
            "support": 2000
        }
    },
    "trec&mr_topk=3_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "dev_mr": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9815,
            "f1-score": 0.9906636386575827,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.948,
            "f1-score": 0.973305954825462,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9865,
            "f1-score": 0.9932041278630759,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.986,
            "f1-score": 0.9929506545820745,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.973,
            "f1-score": 0.9863152559553979,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.988,
            "f1-score": 0.993963782696177,
            "support": 2000
        }
    },
    "trec&sst2_topk=1_nh=1": {
        "accuracy": 0.921,
        "dev_trec": {
            "precision": 0.9252525252525252,
            "recall": 0.916,
            "f1-score": 0.9206030150753768,
            "support": 500
        },
        "dev_sst2": {
            "precision": 0.9168316831683169,
            "recall": 0.926,
            "f1-score": 0.9213930348258706,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9315,
            "f1-score": 0.9645353352316852,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9665,
            "f1-score": 0.9829646580218663,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.956,
            "f1-score": 0.9775051124744376,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9265,
            "f1-score": 0.9618479107189204,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9695,
            "f1-score": 0.9845138359989846,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9245,
            "f1-score": 0.9607690309171213,
            "support": 2000
        }
    },
    "trec&sst2_topk=1_nh=5": {
        "accuracy": 0.963,
        "dev_trec": {
            "precision": 0.9734151329243353,
            "recall": 0.952,
            "f1-score": 0.9625884732052579,
            "support": 500
        },
        "dev_sst2": {
            "precision": 0.9530332681017613,
            "recall": 0.974,
            "f1-score": 0.963402571711177,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9685,
            "f1-score": 0.983997967995936,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9975,
            "f1-score": 0.9987484355444306,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.974,
            "f1-score": 0.9868287740628165,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.962,
            "f1-score": 0.9806320081549439,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9825,
            "f1-score": 0.991172761664565,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9575,
            "f1-score": 0.9782886334610472,
            "support": 2000
        }
    },
    "trec&sst2_topk=1_nh=14": {
        "accuracy": 0.994,
        "dev_trec": {
            "precision": 0.994,
            "recall": 0.994,
            "f1-score": 0.994,
            "support": 500
        },
        "dev_sst2": {
            "precision": 0.994,
            "recall": 0.994,
            "f1-score": 0.994,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9965,
            "f1-score": 0.9982469321312296,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9975,
            "f1-score": 0.9987484355444306,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9955,
            "f1-score": 0.9977449260836884,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.994,
            "f1-score": 0.9969909729187563,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.991,
            "f1-score": 0.9954796584630838,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.987,
            "f1-score": 0.9934574735782586,
            "support": 2000
        }
    },
    "trec&sst2_topk=3_nh=1": {
        "accuracy": 0.927,
        "dev_trec": {
            "precision": 0.9651416122004357,
            "recall": 0.886,
            "f1-score": 0.9238790406673618,
            "support": 500
        },
        "dev_sst2": {
            "precision": 0.8946395563770795,
            "recall": 0.968,
            "f1-score": 0.9298751200768492,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9315,
            "f1-score": 0.9645353352316852,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9815,
            "f1-score": 0.9906636386575827,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.982,
            "f1-score": 0.9909182643794148,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9705,
            "f1-score": 0.9850291804110632,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.985,
            "f1-score": 0.9924433249370278,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.905,
            "f1-score": 0.9501312335958005,
            "support": 2000
        }
    },
    "trec&sst2_topk=3_nh=5": {
        "accuracy": 0.975,
        "dev_trec": {
            "precision": 0.9797979797979798,
            "recall": 0.97,
            "f1-score": 0.9748743718592964,
            "support": 500
        },
        "dev_sst2": {
            "precision": 0.9702970297029703,
            "recall": 0.98,
            "f1-score": 0.9751243781094527,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9735,
            "f1-score": 0.9865720800608057,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.996,
            "f1-score": 0.9979959919839679,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.984,
            "f1-score": 0.9919354838709677,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9745,
            "f1-score": 0.9870853380602685,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.986,
            "f1-score": 0.9929506545820745,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.958,
            "f1-score": 0.9785495403472931,
            "support": 2000
        }
    },
    "trec&sst2_topk=3_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "dev_sst2": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.954,
            "f1-score": 0.9764585465711361,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9485,
            "f1-score": 0.9735694123684885,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.977,
            "f1-score": 0.9883662114314619,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.977,
            "f1-score": 0.9883662114314619,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.929,
            "f1-score": 0.9631933644375325,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9685,
            "f1-score": 0.983997967995936,
            "support": 2000
        }
    },
    "trec&subj_topk=1_nh=1": {
        "accuracy": 0.933,
        "dev_trec": {
            "precision": 0.9338677354709419,
            "recall": 0.932,
            "f1-score": 0.932932932932933,
            "support": 500
        },
        "dev_subj": {
            "precision": 0.9321357285429142,
            "recall": 0.934,
            "f1-score": 0.933066933066933,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.8845,
            "f1-score": 0.938710533297957,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9475,
            "f1-score": 0.9730423620025674,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.917,
            "f1-score": 0.9567031820552947,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.8855,
            "f1-score": 0.9392734022805621,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.951,
            "f1-score": 0.9748846745258841,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9395,
            "f1-score": 0.9688063934003609,
            "support": 2000
        }
    },
    "trec&subj_topk=1_nh=5": {
        "accuracy": 0.963,
        "dev_trec": {
            "precision": 0.96579476861167,
            "recall": 0.96,
            "f1-score": 0.9628886659979938,
            "support": 500
        },
        "dev_subj": {
            "precision": 0.9602385685884692,
            "recall": 0.966,
            "f1-score": 0.963110667996012,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9645,
            "f1-score": 0.9819292440824637,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.956,
            "f1-score": 0.9775051124744376,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.966,
            "f1-score": 0.982706002034588,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.952,
            "f1-score": 0.9754098360655737,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9825,
            "f1-score": 0.991172761664565,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9615,
            "f1-score": 0.9803721641600815,
            "support": 2000
        }
    },
    "trec&subj_topk=1_nh=14": {
        "accuracy": 0.995,
        "dev_trec": {
            "precision": 0.9959919839679359,
            "recall": 0.994,
            "f1-score": 0.994994994994995,
            "support": 500
        },
        "dev_subj": {
            "precision": 0.9940119760479041,
            "recall": 0.996,
            "f1-score": 0.995004995004995,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.977,
            "f1-score": 0.9883662114314619,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.8175,
            "f1-score": 0.8995873452544705,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9865,
            "f1-score": 0.9932041278630759,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9765,
            "f1-score": 0.9881102959777384,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.987,
            "f1-score": 0.9934574735782586,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9855,
            "f1-score": 0.9926970536388819,
            "support": 2000
        }
    },
    "trec&subj_topk=3_nh=1": {
        "accuracy": 0.943,
        "dev_trec": {
            "precision": 0.9763440860215054,
            "recall": 0.908,
            "f1-score": 0.9409326424870466,
            "support": 500
        },
        "dev_subj": {
            "precision": 0.914018691588785,
            "recall": 0.978,
            "f1-score": 0.944927536231884,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.887,
            "f1-score": 0.9401165871754107,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.9745,
            "f1-score": 0.9870853380602685,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.964,
            "f1-score": 0.9816700610997963,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9505,
            "f1-score": 0.9746218918226096,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.9715,
            "f1-score": 0.985544002028912,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9145,
            "f1-score": 0.9553408200574564,
            "support": 2000
        }
    },
    "trec&subj_topk=3_nh=5": {
        "accuracy": 0.976,
        "dev_trec": {
            "precision": 0.9798387096774194,
            "recall": 0.972,
            "f1-score": 0.9759036144578314,
            "support": 500
        },
        "dev_subj": {
            "precision": 0.9722222222222222,
            "recall": 0.98,
            "f1-score": 0.9760956175298804,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.963,
            "f1-score": 0.9811512990320936,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.95,
            "f1-score": 0.9743589743589743,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.9765,
            "f1-score": 0.9881102959777384,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9665,
            "f1-score": 0.9829646580218663,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.982,
            "f1-score": 0.9909182643794148,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.9635,
            "f1-score": 0.9814107461166285,
            "support": 2000
        }
    },
    "trec&subj_topk=3_nh=14": {
        "accuracy": 1.0,
        "dev_trec": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "dev_subj": {
            "precision": 1.0,
            "recall": 1.0,
            "f1-score": 1.0,
            "support": 500
        },
        "test_cr": {
            "precision": 1.0,
            "recall": 0.9795,
            "f1-score": 0.9896438494569336,
            "support": 2000
        },
        "test_mpqa": {
            "precision": 1.0,
            "recall": 0.861,
            "f1-score": 0.9253089736700698,
            "support": 2000
        },
        "test_mr": {
            "precision": 1.0,
            "recall": 0.986,
            "f1-score": 0.9929506545820745,
            "support": 2000
        },
        "test_sst2": {
            "precision": 1.0,
            "recall": 0.9825,
            "f1-score": 0.991172761664565,
            "support": 2000
        },
        "test_subj": {
            "precision": 1.0,
            "recall": 0.984,
            "f1-score": 0.9919354838709677,
            "support": 2000
        },
        "test_trec": {
            "precision": 1.0,
            "recall": 0.979,
            "f1-score": 0.989388580090955,
            "support": 2000
        }
    }
}